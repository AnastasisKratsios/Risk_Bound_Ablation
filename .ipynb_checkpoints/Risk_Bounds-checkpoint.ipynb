{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620e92ab",
   "metadata": {},
   "source": [
    "# Plot Concentration Bound\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f582226",
   "metadata": {},
   "source": [
    "## Geometry of $\\mathcal{X}\\times \\mathcal{Y}$: \n",
    "### Set the Rate at Which Embedding Distorts Geometry in As a Function of Euclidean Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3d602",
   "metadata": {},
   "source": [
    "We consider four possible cases (``distortion_type``):\n",
    "1. Worst-case (expander graph-type geometries)\n",
    "2. Polynomial embedding (trees).\n",
    "3. Subsets of Euclidean space.\n",
    "4. Subspaces (metric) of the real line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21df6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_type = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653952f8",
   "metadata": {},
   "source": [
    "### Decide on N vs k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690377b6",
   "metadata": {},
   "source": [
    "### N\n",
    "Once the number of training samples, $N$, is set then, we consider two scenarios:\n",
    "- if ``N_is_Small==True``: $N$ ranges from $\\lfloor N/10 \\rfloor$ to $N$\n",
    "- if ``N_is_Small==True``: $N$ ranges from $N^3$ to $N^4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95290bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1*(10**4)\n",
    "N_is_Small = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ceb87",
   "metadata": {},
   "source": [
    "### k\n",
    "\n",
    "#### Either we set k manually or we consider the no. Points Needed to Pack a Cube:\n",
    "\n",
    "From [George G. Lorentz, Manfred v. Golitschek, and Yuly Makovoz. Constructive approximation - Proposition 1.3](https://link.springer.com/book/9783642646102) the packing number of $[0,\\operatorname{diam}]^d$ in $\\ell_{\\infty}^d$ by $\\ell_{\\infty}^d$-balls of radius $10^{-p}$ is no more than\n",
    "$$\n",
    "k \\ge \n",
    "\\Big\\lceil\n",
    "2^{-d}\n",
    "        \\,\n",
    "        \\Big(10^{p}*\\operatorname{diam}\\Big)^d\n",
    "\\Big\\rceil\n",
    "$$\n",
    "we use this lower-bound to compute $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d98e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototypical Space: [0,1]^10\n",
      "Distance Between Points on the Grid: 1e-10\n",
      "Number of points:9.77e+96\n"
     ]
    }
   ],
   "source": [
    "# Cube or no Cube?\n",
    "cube_k = True\n",
    "# If Manual \n",
    "k_manual = 1*(10**8)\n",
    "\n",
    "# If Cube\n",
    "diam = 1*(10**0)\n",
    "d = 1*(10**1); print('Prototypical Space: [0,'+str(diam)+']^'+str(d))\n",
    "p = 1*(10**1); print('Distance Between Points on the Grid: '+str(10**-p))\n",
    "# Use less points (w.o. 2^-d factor)\n",
    "use_no_2d_factor = True\n",
    "\n",
    "%run ./SupportFiles/Compute_N_points.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaca908",
   "metadata": {},
   "source": [
    "## Import Packages and Set Global Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a60a845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependancies and Packages Loaded\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "%run ./SupportFiles/Dependancies.ipynb\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e15057",
   "metadata": {},
   "source": [
    "# Set Global Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19617975",
   "metadata": {},
   "source": [
    "## Are we Computing Risk Bounds or Concentration Bounds (in $\\mathcal{W}_1$)?\n",
    "- For Risk Bounds set: True\n",
    "- For Concentration Bounds set: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72f0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk_or_Concentration = True\n",
    "Isometric_Embedding = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a161c81",
   "metadata": {},
   "source": [
    "#### Decide on How Many Points to Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe17fb1",
   "metadata": {},
   "source": [
    "Load Global hyperparameters, now that internal parameters have been defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e84337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./SupportFiles/Global_Hyperparameters.ipynb\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc982ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec195e",
   "metadata": {},
   "source": [
    "Load helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---')\n",
    "%run ./SupportFiles/Helper_Functions.ipynb\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06efb2",
   "metadata": {},
   "source": [
    "# The Risk Bound Computers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1aeb5f",
   "metadata": {},
   "source": [
    "We compare our risk bound against the following binary classification benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc565b3",
   "metadata": {},
   "source": [
    "## Benchmark: Trivial VC/Occam Bound (Binary Classification)\n",
    "From the The (Quantitative) Fundamental Theorem of Statistical Learning ([Theorem 6.8 in \"Understanding Machine Learning\" (with extra details in Section 28.1)](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kezPqwoAAAAJ&citation_for_view=kezPqwoAAAAJ:XiVPGOgt02cC)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathcal{R}(f) - \\hat{\\mathcal{R}}(f)\n",
    "\\le &\n",
    "    n^{-1/2}\n",
    "    (\n",
    "        128 \\operatorname{VC-dim}\\log(n+1) + \\log(8/\\delta)\n",
    "    )^{1/2}\n",
    "\\\\ \n",
    "\\le & \n",
    "    n^{-1/2}\n",
    "    (\n",
    "        128 \\#\\mathcal{X}\\log(n+1) + \\log(8/\\delta)\n",
    "    )^{1/2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "where we use the fact that $\\operatorname{VC-dim}(2^{\\mathcal{X}})\\le \\log_2(\\#2^{\\mathcal{X}})=\\#\\mathcal{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a46477",
   "metadata": {},
   "source": [
    "## Hoeffding Bound\n",
    "\n",
    "\n",
    "From [Corollary 4.6 of \"Understanding Machine Learning\"](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kezPqwoAAAAJ&citation_for_view=kezPqwoAAAAJ:XiVPGOgt02cC) we have the following Heofding-type bound\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    (2n)^{-1/2}\n",
    "    \\log\\big(\n",
    "    2 \\times 2^k/\\delta\n",
    "    \\big)^{1/2}\n",
    "    = \n",
    "    (2n)^{-1/2}\n",
    "     \\big(\n",
    "     \\log(2/\\delta) + k\\log(2)\n",
    "     \\big)^{1/2}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6653302",
   "metadata": {},
   "source": [
    "Load risk bound functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./SupportFiles/Risk_Bound_Engine.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2e371",
   "metadata": {},
   "source": [
    "## Generate Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc1787",
   "metadata": {},
   "source": [
    "#### Decide on Scale of Sample Size (Range: Small N or Large N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93333de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices\n",
    "Freq_plot = 100\n",
    "indexing_set = range(1,10000,Freq_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5196884",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print_Occam = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed0591",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.title(''+dist_name+', k='+str('{:.2e}'.format(k))+', Varying F and N')\n",
    "    \n",
    "\n",
    "plt.xlabel('No. Samples (N)')\n",
    "plt.ylabel('Risk Bound')# on $\\sup_{f\\in \\mathcal{F}}\\,|\\mathcal{R}(\\hat{f})-\\hat{\\mathcal{R}}(\\hat{f})|$')\n",
    "# plt.ylabel('Bound on $\\mathbb{E}[\\mathcal{W}_1(\\mathbb{P},\\mathbb{P}^N)]$')\n",
    "\n",
    "\n",
    "\n",
    "# Set Max No Colours\n",
    "n_col=max(indexing_set)+2\n",
    "\n",
    "\n",
    "#### Plot Generation\n",
    "for i in indexing_set:\n",
    "    # Set Value of F\n",
    "    F_global = int(np.round(i,0))\n",
    "    \n",
    "    # Write Function of N only\n",
    "    def get_risk_bound__NVar_scalar(N):\n",
    "        return get_risk_bound__scalar(k=k_global,F=F_global,N=N)\n",
    "    \n",
    "    get_risk_bound__NVar = np.vectorize(get_risk_bound__NVar_scalar)\n",
    "    \n",
    "    # Compute Risk Bound\n",
    "    Risk_Bounds = get_risk_bound__NVar_scalar(N_sequence)\n",
    "\n",
    "    \n",
    "    # Plot\n",
    "    col_index = (i-min(indexing_set))/(max(indexing_set)+1)\n",
    "    # Plot Risk-Bound\n",
    "    if i % (Freq_plot*10) == 1: # Ony write every other legend\n",
    "        plt.plot(N_sequence, \n",
    "             Risk_Bounds,\n",
    "             color=colorFader(c1,c2,col_index),\n",
    "             label = 'F='+str(F_global).format(i=i))\n",
    "    else: # Remove legend on most plots\n",
    "        plt.plot(N_sequence, \n",
    "             Risk_Bounds,\n",
    "             color=colorFader(c1,c2,col_index),label='_nolegend_')\n",
    "\n",
    "\n",
    "### Classical Risk-Bounds for Binary Classification\n",
    "if Y_is_bin_class == True:\n",
    "    if Print_Occam:\n",
    "        ###----------------###\n",
    "        ### VC/Occam Bound ###\n",
    "        ###----------------###\n",
    "        # Write Function of N only\n",
    "        def get_risk_bound__VC_scalar(N):\n",
    "            return trivial_VCBound(N_in=N,k_in=k,delta = delta)\n",
    "        get_risk_bound__VC = np.vectorize(get_risk_bound__VC_scalar)\n",
    "\n",
    "        # Compute Risk Bound\n",
    "        Risk_Bounds__VC = get_risk_bound__VC(N_sequence)\n",
    "\n",
    "        # Plot Risk-Bound\n",
    "        plt.plot(N_sequence,Risk_Bounds__VC,label = 'Occam',c='orange',linewidth=3)\n",
    "    ###-----------------###\n",
    "    ### Hoeffding Bound ###\n",
    "    ###-----------------###\n",
    "    # Write Function of N only\n",
    "    def get_risk_bound__Hoeffding_scalar(N):\n",
    "        return Hoeffding_Bound(N_in=N,k_in=k,delta = delta)\n",
    "    get_risk_bound__Hoeffding = np.vectorize(get_risk_bound__Hoeffding_scalar)\n",
    "    \n",
    "    # Compute Risk Bound\n",
    "    Risk_Bounds__Hoeffding = get_risk_bound__Hoeffding(N_sequence)\n",
    "    \n",
    "    # Plot Risk-Bound\n",
    "    plt.plot(N_sequence,Risk_Bounds__Hoeffding,label = 'Hoeffding',c='red',linewidth=3)\n",
    "\n",
    "# plt.legend(loc=0) #'best'\n",
    "plt.legend(loc=1) #'Upper right'\n",
    "# plt.legend(loc=2) # 'Upper left'\n",
    "\n",
    "\n",
    "# ------------------- #\n",
    "# Our Risk-Bound Only #\n",
    "# ------------------- #\n",
    "sns.set_style(\"whitegrid\")\n",
    "axes1 = ax.add_axes([0.2, 0.2, 0.3, 0.3]) # inset axes (location first, size second)\n",
    "# axes1.set_title('Bound',fontsize=15)\n",
    "\n",
    "#### Plot Generation\n",
    "for i in indexing_set:\n",
    "    # Set Value of F\n",
    "    F_global = int(np.round(i,0))\n",
    "    \n",
    "    # Write Function of N only\n",
    "    def get_risk_bound__NVar_scalar(N):\n",
    "        return get_risk_bound__scalar(k=k_global,F=F_global,N=N)\n",
    "    \n",
    "    get_risk_bound__NVar = np.vectorize(get_risk_bound__NVar_scalar)\n",
    "    \n",
    "    # Compute Risk Bound\n",
    "    Risk_Bounds = get_risk_bound__NVar_scalar(N_sequence)\n",
    "\n",
    "    \n",
    "    # Plot\n",
    "    col_index = (i-min(indexing_set))/(max(indexing_set)+1)\n",
    "    plt.plot(N_sequence, Risk_Bounds,label = 'F='+str(F_global).format(i=i),color=colorFader(c1,c2,col_index))\n",
    "\n",
    "if Y_is_bin_class == True:\n",
    "    ###-----------------###\n",
    "    ### Hoeffding Bound ###\n",
    "    ###-----------------###\n",
    "    # Write Function of N only\n",
    "    def get_risk_bound__Hoeffding_scalar(N):\n",
    "        return Hoeffding_Bound(N_in=N,k_in=k,delta = delta)\n",
    "    get_risk_bound__Hoeffding = np.vectorize(get_risk_bound__Hoeffding_scalar)\n",
    "    \n",
    "    # Compute Risk Bound\n",
    "    Risk_Bounds__Hoeffding = get_risk_bound__Hoeffding(N_sequence)\n",
    "    \n",
    "    # Plot Risk-Bound\n",
    "    plt.plot(N_sequence,Risk_Bounds__Hoeffding,label = 'Hoeffding',c='red',linewidth=3)\n",
    "\n",
    "# ---------------------------------------- #\n",
    "# High Representation Space Dimension Only #\n",
    "# ---------------------------------------- #\n",
    "sns.set_style(\"ticks\")\n",
    "axes2 = ax.add_axes([0.44, 0.55, 0.3, 0.3]) # inset axes (location first, size second)\n",
    "axes2.set_title('Large Rep. Dim.',fontsize=15)\n",
    "\n",
    "#### Plot Generation\n",
    "for i in indexing_set[-int(len(indexing_set)/10):]:\n",
    "    # Set Value of F\n",
    "    F_global = int(np.round(i,0))\n",
    "    \n",
    "    # Write Function of N only\n",
    "    def get_risk_bound__NVar_scalar(N):\n",
    "        return get_risk_bound__scalar(k=k_global,F=F_global,N=N)\n",
    "    \n",
    "    get_risk_bound__NVar = np.vectorize(get_risk_bound__NVar_scalar)\n",
    "    \n",
    "    # Compute Risk Bound\n",
    "    Risk_Bounds = get_risk_bound__NVar_scalar(N_sequence)\n",
    "\n",
    "    \n",
    "    # Plot\n",
    "    col_index = (i-min(indexing_set))/(max(indexing_set)+1)\n",
    "    plt.plot(N_sequence, Risk_Bounds,label = 'F='+str(F_global).format(i=i),color=colorFader(c1,c2,col_index))\n",
    "\n",
    "    \n",
    "    \n",
    "plt.xlabel('No. Samples (N)',fontsize=10)\n",
    "plt.ylabel('Risk Bound',fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# ----------------------------------------------------- #\n",
    "\n",
    "plt.savefig('Experiments/Risk_Bound_F/WBenchmarks__NF_kis'+str(k_global)+'____'+str(dist_name)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe786fcd",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin #\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9a454",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e7eca",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
